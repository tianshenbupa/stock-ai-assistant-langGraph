from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from typing import List, Optional
from loguru import logger
from pathlib import Path
from config.settings import settings
from src.rag.loader import FinancialReportLoader


class RAGRetriever:
    """RAG æ£€ç´¢å™¨"""

    def __init__(self):
        self.vector_store_path = settings.VECTOR_STORE_PATH
        self.embedding_model = settings.EMBEDDING_MODEL
        self.embeddings = None
        self.vector_store = None
        self._initialized = False

    def initialize(self, force_reload: bool = False):
        """
        åˆå§‹åŒ– RAG ç³»ç»Ÿ

        Args:
            force_reload: æ˜¯å¦å¼ºåˆ¶é‡æ–°åŠ è½½æ–‡æ¡£
        """
        try:
            logger.info("ðŸš€ åˆå§‹åŒ– RAG ç³»ç»Ÿ...")

            # åˆå§‹åŒ–åµŒå…¥æ¨¡åž‹
            logger.info(f"ðŸ“¥ åŠ è½½åµŒå…¥æ¨¡åž‹: {self.embedding_model}")
            self.embeddings = HuggingFaceEmbeddings(
                model_name=self.embedding_model,
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )

            # æ£€æŸ¥å‘é‡åº“æ˜¯å¦å­˜åœ¨
            import os
            vector_store_exists = os.path.exists(self.vector_store_path)

            # ===== ðŸ”§ ä¿®æ”¹è¿™éƒ¨åˆ†é€»è¾‘ =====
            if vector_store_exists and not force_reload:
                logger.info("ðŸ“š åŠ è½½å·²å­˜åœ¨çš„å‘é‡æ•°æ®åº“...")
                self.vector_store = Chroma(
                    persist_directory=self.vector_store_path,
                    embedding_function=self.embeddings
                )

                # âœ… æ£€æŸ¥å‘é‡åº“æ˜¯å¦ä¸ºç©º
                collection_count = self.vector_store._collection.count()

                if collection_count == 0:
                    logger.warning("âš ï¸  å‘é‡åº“ä¸ºç©ºï¼Œå°è¯•åŠ è½½æ–‡æ¡£...")
                    self._load_and_add_documents()
                else:
                    logger.info(f"ðŸ“š å‘é‡åº“å·²åŒ…å« {collection_count} ä¸ªæ–‡æ¡£å—")
            else:
                logger.info("ðŸ“„ åˆ›å»ºæ–°çš„å‘é‡æ•°æ®åº“å¹¶åŠ è½½æ–‡æ¡£...")
                self._load_and_add_documents()
            # ===== ç»“æŸä¿®æ”¹ =====

            self._initialized = True
            collection_count = self.vector_store._collection.count()
            logger.info(f"âœ… RAG ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œå‘é‡åº“åŒ…å« {collection_count} ä¸ªæ–‡æ¡£å—")

        except Exception as e:
            logger.error(f"âŒ RAG åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            raise

    def _load_and_add_documents(self):
        """
        åŠ è½½å¹¶æ·»åŠ æ–‡æ¡£åˆ°å‘é‡åº“ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
        """
        try:
            loader = FinancialReportLoader()
            documents = loader.load_documents()

            if not documents:
                logger.warning("âš ï¸  æ²¡æœ‰å¯ç”¨çš„æ–‡æ¡£")
                pdf_dir = Path(settings.PDF_DIRECTORY)
                logger.info(f"ðŸ’¡ æç¤º: è¯·å°† PDF è´¢æŠ¥æ”¾å…¥ {pdf_dir.absolute()}")

                # åˆ›å»ºç©ºå‘é‡åº“
                if self.vector_store is None:
                    self.vector_store = Chroma(
                        persist_directory=self.vector_store_path,
                        embedding_function=self.embeddings
                    )
            else:
                logger.info(f"ðŸ“¥ æ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£å—åˆ°å‘é‡åº“...")

                if self.vector_store is None:
                    # ç¬¬ä¸€æ¬¡åˆ›å»º
                    self.vector_store = Chroma.from_documents(
                        documents=documents,
                        embedding=self.embeddings,
                        persist_directory=self.vector_store_path
                    )
                else:
                    # æ·»åŠ åˆ°çŽ°æœ‰å‘é‡åº“
                    self.vector_store.add_documents(documents)

                # âŒ ç§»é™¤è¿™è¡Œ
                # self.vector_store.persist()

                # âœ… æ–°ç‰ˆæœ¬çš„ Chroma ä¼šè‡ªåŠ¨æŒä¹…åŒ–,ä¸éœ€è¦æ‰‹åŠ¨è°ƒç”¨
                logger.info(f"âœ… æ–‡æ¡£åŠ è½½å®Œæˆ")

        except Exception as e:
            logger.error(f"âŒ æ–‡æ¡£åŠ è½½å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())

            # ç¡®ä¿è‡³å°‘åˆ›å»ºç©ºå‘é‡åº“
            if self.vector_store is None:
                self.vector_store = Chroma(
                    persist_directory=self.vector_store_path,
                    embedding_function=self.embeddings
                )

    def query(self, query: str, top_k: int = 5, stock_ticker: Optional[str] = None) -> List[dict]:
        """
        æ£€ç´¢ç›¸å…³æ–‡æ¡£

        Args:
            query: æŸ¥è¯¢é—®é¢˜
            top_k: è¿”å›žç»“æžœæ•°é‡
            stock_ticker: è‚¡ç¥¨ä»£ç è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰

        Returns:
            ç›¸å…³æ–‡æ¡£åˆ—è¡¨
        """
        if not self._initialized:
            raise RuntimeError("RAG ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ initialize()")

        try:
            # æž„å»ºè¿‡æ»¤æ¡ä»¶
            filter_dict = None
            if stock_ticker:
                logger.info(f"ðŸ” æ£€ç´¢è‚¡ç¥¨ {stock_ticker} ç›¸å…³æ–‡æ¡£")

            # æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
            results = self.vector_store.similarity_search_with_score(
                query=query,
                k=top_k,
                filter=filter_dict
            )

            # æ ¼å¼åŒ–ç»“æžœ
            formatted_results = []
            for doc, score in results:
                formatted_results.append({
                    "content": doc.page_content,
                    "metadata": doc.metadata,
                    "similarity_score": float(score)
                })

            logger.info(f"âœ… æ£€ç´¢åˆ° {len(formatted_results)} ä¸ªç›¸å…³æ–‡æ¡£")
            return formatted_results

        except Exception as e:
            logger.error(f"âŒ æ£€ç´¢å¤±è´¥: {e}")
            return []

    def get_context_for_agent(self, query: str, stock_ticker: str, top_k: int = 3) -> str:
        """
        ä¸ºä»£ç†èŽ·å–ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²

        Args:
            query: æŸ¥è¯¢é—®é¢˜
            stock_ticker: è‚¡ç¥¨ä»£ç 
            top_k: è¿”å›žç»“æžœæ•°é‡

        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        results = self.query(query, top_k, stock_ticker)

        if not results:
            return "æœªæ‰¾åˆ°ç›¸å…³è´¢æŠ¥ä¿¡æ¯ã€‚"

        context_parts = ["ä»¥ä¸‹æ˜¯ä»Žè´¢æŠ¥ä¸­æ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯ï¼š\n"]
        for i, result in enumerate(results, 1):
            context_parts.append(f"\nã€æ–‡æ¡£ {i}ã€‘")
            context_parts.append(f"å†…å®¹ï¼š{result['content'][:500]}...")  # é™åˆ¶é•¿åº¦
            context_parts.append(f"ç›¸ä¼¼åº¦ï¼š{result['similarity_score']:.4f}\n")

        return "\n".join(context_parts)

    @property
    def is_initialized(self) -> bool:
        return self._initialized

    @property
    def collection_size(self) -> int:
        if not self._initialized or not self.vector_store:
            return 0
        try:
            return self.vector_store._collection.count()
        except:
            return 0


# å…¨å±€ RAG å®žä¾‹
rag_retriever = RAGRetriever()